{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Looking_Fruit_nbk.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "yK-K0_Oxp9RI",
        "Yujoou29mCFK",
        "2y7AyVsDpMeK"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ishandandekar/Looking-Fruit/blob/main/Looking_Fruit_nbk.ipynb)"
      ],
      "metadata": {
        "id": "uNrJinLmAcVX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Looking_Fruit\n",
        "\n",
        "ðŸ‘‹ Hello and welcome to the **Looking_Fruit** notebook. In this notebook I try to replicate the [Fruits-360](https://www.researchgate.net/publication/321475443_Fruit_recognition_from_images_using_deep_learning) research paper. In this paper, researchers have tried to classify images of **131** fruits and vegetables. The data used for these modelling experiments is provided by the paper researchers themselves."
      ],
      "metadata": {
        "id": "2t7p4-GpnQFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for GPU\n",
        "!nvidia-smi -L"
      ],
      "metadata": {
        "id": "6fVSgcHVkTpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 0: Defining the problem\n"
      ],
      "metadata": {
        "id": "yK-K0_Oxp9RI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Objective:**  \n",
        "To classify the images of various fruits and vegetables with best f1-score.  \n",
        "\n",
        "**Files:**\n",
        "- *Train*: This folder contains folders labelled as fruit's/vegetable's name. These subfolders contain images of the respective fruit/vegetable. This folder will be used for training purpose.\n",
        "- *Test*: This folder contains folders labelled as fruit's/vegetable's name. These subfolders contain images of the respective fruit/vegetable. This folder will be used for testing purpose."
      ],
      "metadata": {
        "id": "E957ywbEkgil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Getting the data\n",
        "The data used for this project is publicaly available on [Kaggle](https://www.kaggle.com/datasets/ishandandekar/fruitimagedataset).\n",
        "\n",
        "- Use Kaggle's API to download the data into Colab.\n",
        "- Get utility functions to help in future.\n",
        "- Configure data files to read using Python.\n"
      ],
      "metadata": {
        "id": "Yujoou29mCFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the helper functions script\n",
        "!wget https://raw.githubusercontent.com/ishandandekar/Looking-Fruit/main/helper_functions.py\n",
        "\n",
        "# Get the necessary functions from the python script\n",
        "from helper_functions import plot_loss_curves, unzip_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RriztHP9nLy1",
        "outputId": "997a6433-f335-4764-e06b-65a0f7874fb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-21 18:21:36--  https://raw.githubusercontent.com/ishandandekar/Looking-Fruit/main/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1215 (1.2K) [text/plain]\n",
            "Saving to: â€˜helper_functions.pyâ€™\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]   1.19K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-08-21 18:21:36 (32.6 MB/s) - â€˜helper_functions.pyâ€™ saved [1215/1215]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the kaggle library\n",
        "!pip install -q kaggle\n",
        "\n",
        "# Upload the Kaggle API keys\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "!mkdir ~/.kaggle\n",
        "\n",
        "# Copy the json file to the folder\n",
        "!cp kaggle.json ~/.kaggle\n",
        "\n",
        "# Change permissions for json to work with the Kaggle API\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Download the dataset\n",
        "!kaggle datasets download -d ishandandekar/fruitimagedataset\n",
        "\n",
        "# Unzip data\n",
        "unzip_data('fruitimagedataset.zip')"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "QxwTbHhbniZd",
        "outputId": "d3bac89b-21f0-40d0-83f1-99f3bbed2b1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-999f3e6e-c4b2-4e01-aa48-fdb55560f313\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-999f3e6e-c4b2-4e01-aa48-fdb55560f313\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Downloading fruitimagedataset.zip to /content\n",
            " 97% 385M/398M [00:02<00:00, 124MB/s]\n",
            "100% 398M/398M [00:02<00:00, 165MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Know more about the data\n",
        "\n",
        "- Get the statistics about the data.\n",
        "- Check if the labels are imbalanced.\n",
        "- Visualize random samples in data.\n",
        "- (*If required*) Trim data.\n",
        "- (*If required*) Preprocess the data.\n",
        "- Make data processing faster using `ImageDataGenerator`."
      ],
      "metadata": {
        "id": "2y7AyVsDpMeK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "rruTT4WnpvsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up necessary variables\n",
        "TRAIN_PATH = '/content/data/train/train'\n",
        "TEST_PATH = '/content/data/test/test'"
      ],
      "metadata": {
        "id": "Jgdo_iPQp-hw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the number of classes\n",
        "classes = []\n",
        "\n",
        "for dirname, _, filenames in os.walk('/content/data'):\n",
        "    if dirname.startswith(TRAIN_PATH):\n",
        "        classes.append(dirname[len(TRAIN_PATH):])\n",
        "\n",
        "print(f\"Total number of classes to deal with: {len(classes)}\")"
      ],
      "metadata": {
        "id": "uJI7iNbnqHOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show random classes present in the dataset\n",
        "list_of_five_random_labels = random.sample(labels,5)\n",
        "list_of_five_random_labels"
      ],
      "metadata": {
        "id": "_FaY0ocUwKP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of images of each fruit/vegetable as a pandas.DataFrame\n",
        "\n",
        "# List to append the count of images\n",
        "number_of_images_train = []\n",
        "\n",
        "for label in classes:\n",
        "    path = f'{TRAIN_PATH}/{label}'\n",
        "    count = len(os.listdir(path))\n",
        "    number_of_images_train.append(count)\n",
        "\n",
        "train_image_count_df = pd.DataFrame({\"Label\":classes,\"Number of Images\":number_of_images_train})\n",
        "\n",
        "# To view first 10 rows of the dataframe\n",
        "train_image_count_df.head(10)"
      ],
      "metadata": {
        "id": "fl9ktKX6wiaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Label with most number of images\n",
        "print(f\"Label with most number of images:\")\n",
        "print(train_images_count_df.sort_values(\"Number of Images\",ascending=False).head(1))\n",
        "print(f\"Label with least number of images:\")\n",
        "print(train_images_count_df.sort_values(\"Number of Images\",ascending=True).head(1))"
      ],
      "metadata": {
        "id": "6L99UaG5iyQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show random sample from training of a random fruit/vegetable\n",
        "\n",
        "random_label = random.choice(labels)\n",
        "sample_path = f'{TRAIN_PATH}/{label}'\n",
        "random_image= random.choice(os.listdir(sample_path))\n",
        "random_image_path = f'{sample_path}/{random_image}'\n",
        "\n",
        "img = mpimg.imread(random_image_path)\n",
        "imgplot = plt.imshow(img)\n",
        "plt.axis(False)\n",
        "plt.title(f'{label}')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Cv6G8PcTwtGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating ImageDataGenerators for better data processing\n",
        "\n",
        "# Image size has been specified in the research paper\n",
        "IMAGE_SIZE = (100,100)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_datagen = ImageDataGenerator(width_shift_range=0,\n",
        "                                   height_shift_range=0,\n",
        "                                   zoom_range=0,\n",
        "                                   horizontal_flip=0,\n",
        "                                   vertical_flip=0)\n",
        "\n",
        "# Need the test data as is, but need to make it process faster\n",
        "test_datagen = ImageDataGenerator()\n",
        "\n",
        "train_gen = train_datagen.flow_from_directory(TRAIN_PATH,\n",
        "                                              labels='inferred',\n",
        "                                              target_size=IMAGE_SIZE,\n",
        "                                              class_mode='sparse',\n",
        "                                              batch_size=BATCH_SIZE,\n",
        "                                              shuffle=True,\n",
        "                                              classes=classes)\n",
        "\n",
        "test_gen = test_datagen.flow_from_directory(TEST_PATH,\n",
        "                                            labels='inferred',\n",
        "                                            target_size=IMAGE_SIZE,\n",
        "                                            class_mode='sparse',\n",
        "                                            batch_size=BATCH_SIZE,\n",
        "                                            shuffle=False,\n",
        "                                            classes=classes)"
      ],
      "metadata": {
        "id": "cbJoJNH-xqYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Describing modelling experiments"
      ],
      "metadata": {
        "id": "yDtentj-5F-0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- This notebook contains 7 models built to get the best **f1-score** on the test dataset. These models also include the models made by the researchers themselves.  \n",
        "- Models to be made:\n",
        "  1. **Model 0** : A simple model with fully connected multiple Dense layers; this model acts as a baseline.\n",
        "  1. **Model 1** : 2 pairs of CNN and MaxPool layers with a Flatten layer and Dense layer in the end for classification.\n",
        "  1. **Model 2** : Multiple CNN layers, MaxPool layers with a Flatten layer and Dense layer in the end; *should get better results from this.*\n",
        "  1. **Model 3** : Using transfer learning, exploit ResNet model for classification.\n",
        "  1. **Model 4** : Using transfer learning, exploit EfficientNetBx for classification.\n",
        "  1. **Model 5** : Use fine-tuned ResNet model for classification.\n",
        "  1. **Model 6** : Use fine-tuned EfficientNetBx for classification.\n",
        "- Get classification metrics for each model.\n"
      ],
      "metadata": {
        "id": "CsIhGbL_5xsc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 0"
      ],
      "metadata": {
        "id": "gr5XC0Uq_-yC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 1"
      ],
      "metadata": {
        "id": "bTZ_xAlHADd4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 2"
      ],
      "metadata": {
        "id": "7Z-aHSMMAEXj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 3"
      ],
      "metadata": {
        "id": "hdsfE1MCAFbK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 4"
      ],
      "metadata": {
        "id": "YY9ejPFFAGUv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 5"
      ],
      "metadata": {
        "id": "8YIH9eT5AHdM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 6"
      ],
      "metadata": {
        "id": "Y4hHsWiWAIqr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Compare results and conclude experiments\n",
        "- Test each model on the given test dataset.\n",
        "- Use graphs and matrices to visualize results.\n",
        "- (*Optional*) Tune hyperparameters of the best model.\n",
        "- Compare best models results with researchers best model.\n",
        "- Export the best model.\n"
      ],
      "metadata": {
        "id": "uhXoIl1T_Ju3"
      }
    }
  ]
}