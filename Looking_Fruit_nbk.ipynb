{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "yK-K0_Oxp9RI",
        "Yujoou29mCFK",
        "2y7AyVsDpMeK"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ishandandekar/Looking-Fruit/blob/main/Looking_Fruit_nbk.ipynb)"
      ],
      "metadata": {
        "id": "uNrJinLmAcVX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Looking_Fruit\n",
        "\n",
        "ðŸ‘‹ Hello and welcome to the **Looking_Fruit** notebook. In this notebook I try to replicate the [Fruits-360](https://www.researchgate.net/publication/321475443_Fruit_recognition_from_images_using_deep_learning) research paper. In this paper, researchers have tried to classify images of **131** fruits and vegetables. The data used for these modelling experiments is provided by the paper researchers themselves."
      ],
      "metadata": {
        "id": "2t7p4-GpnQFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for GPU\n",
        "!nvidia-smi -L"
      ],
      "metadata": {
        "id": "6fVSgcHVkTpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 0: Defining the problem\n"
      ],
      "metadata": {
        "id": "yK-K0_Oxp9RI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Objective:**  \n",
        "To classify the images of various fruits and vegetables with best f1-score.  \n",
        "\n",
        "**Files:**\n",
        "- *Train*: This folder contains folders labelled as fruit's/vegetable's name. These subfolders contain images of the respective fruit/vegetable. This folder will be used for training purpose.\n",
        "- *Test*: This folder contains folders labelled as fruit's/vegetable's name. These subfolders contain images of the respective fruit/vegetable. This folder will be used for testing purpose."
      ],
      "metadata": {
        "id": "E957ywbEkgil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Getting the data\n",
        "The data used for this project is publicly available on [Kaggle](https://www.kaggle.com/datasets/ishandandekar/fruitimagedataset).\n",
        "\n",
        "- Use Kaggle's API to download the data into Colab.\n",
        "- Get utility functions to help in future.\n",
        "- Configure data files to read using Python.\n"
      ],
      "metadata": {
        "id": "Yujoou29mCFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the helper functions script\n",
        "!wget https://raw.githubusercontent.com/ishandandekar/Looking-Fruit/main/helper_functions.py\n",
        "\n",
        "# Get the necessary functions from the python script\n",
        "from helper_functions import plot_loss_curves, unzip_data, create_model_checkpoint, get_metrics"
      ],
      "metadata": {
        "id": "RriztHP9nLy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "About these helper functions (see documentation for better description):\n",
        "* **plot_loss_curves** : Plots a line graph (using matplotlib) to see changes in loss and accuracy during training.\n",
        "* **unzip_data** : Unzips a zip file to a directory\n",
        "* **create_model_checkpoint** : Create a model checkpoint with only best weights (monitored over validation loss)."
      ],
      "metadata": {
        "id": "AQk2Ny-zWEtP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the kaggle library\n",
        "!pip install -q kaggle\n",
        "\n",
        "# Upload the Kaggle API keys\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "!mkdir ~/.kaggle\n",
        "\n",
        "# Copy the json file to the folder\n",
        "!cp kaggle.json ~/.kaggle\n",
        "\n",
        "# Change permissions for json to work with the Kaggle API\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Download the dataset\n",
        "!kaggle datasets download -d ishandandekar/fruitimagedataset\n",
        "\n",
        "# Unzip data\n",
        "unzip_data('fruitimagedataset.zip', data_dir=\"raw\")"
      ],
      "metadata": {
        "id": "QxwTbHhbniZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Know more about the data\n",
        "\n",
        "- Get the statistics about the data.\n",
        "- Check if the labels are imbalanced.\n",
        "- Visualize random samples in data.\n",
        "- (*If required*) Trim data.\n",
        "- (*If required*) Preprocess the data.\n",
        "- Make data processing faster using `ImageDataGenerator`."
      ],
      "metadata": {
        "id": "2y7AyVsDpMeK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers\n",
        "from keras.utils import plot_model"
      ],
      "metadata": {
        "id": "rruTT4WnpvsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up necessary variables\n",
        "TRAIN_PATH = '/content/raw/train/train/'\n",
        "TEST_PATH = '/content/raw/test/test/'\n",
        "RAW_DATA_PATH = '/content/raw'"
      ],
      "metadata": {
        "id": "Jgdo_iPQp-hw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the number of classes\n",
        "classes = []\n",
        "\n",
        "for dirname, _, filenames in os.walk(RAW_DATA_PATH):\n",
        "    if dirname.startswith(f\"{TRAIN_PATH}\"):\n",
        "        classes.append(dirname[len(TRAIN_PATH):])\n",
        "\n",
        "print(f\"Total number of classes to deal with: {len(classes)}\")"
      ],
      "metadata": {
        "id": "uJI7iNbnqHOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show random classes present in the dataset\n",
        "list_of_five_random_labels = random.sample(classes,5)\n",
        "list_of_five_random_labels"
      ],
      "metadata": {
        "id": "_FaY0ocUwKP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of images of each fruit/vegetable as a pandas.DataFrame\n",
        "\n",
        "# List to append the count of images\n",
        "number_of_images_train = []\n",
        "\n",
        "for label in classes:\n",
        "    path = f'{TRAIN_PATH}/{label}'\n",
        "    count = len(os.listdir(path))\n",
        "    number_of_images_train.append(count)\n",
        "\n",
        "train_image_count_df = pd.DataFrame({\"Label\":classes,\"Number of Images\":number_of_images_train})\n",
        "\n",
        "# To view first 10 rows of the dataframe\n",
        "train_image_count_df.head(10)"
      ],
      "metadata": {
        "id": "fl9ktKX6wiaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Label with most number of images\n",
        "print(f\"Label with most number of images:\")\n",
        "print(train_image_count_df.sort_values(\"Number of Images\",ascending=False).head(1))\n",
        "print(f\"Label with least number of images:\")\n",
        "print(train_image_count_df.sort_values(\"Number of Images\",ascending=True).head(1))"
      ],
      "metadata": {
        "id": "6L99UaG5iyQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show random sample from training of a random fruit/vegetable\n",
        "\n",
        "random_label = random.choice(classes)\n",
        "sample_path = f'{TRAIN_PATH}/{random_label}'\n",
        "random_image= random.choice(os.listdir(sample_path))\n",
        "random_image_path = f'{sample_path}/{random_image}'\n",
        "\n",
        "img = mpimg.imread(random_image_path)\n",
        "imgplot = plt.imshow(img)\n",
        "plt.axis(False)\n",
        "plt.title(f'{random_label}')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Cv6G8PcTwtGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making new directories for trimmed training data\n",
        "os.mkdir(\"data\")\n",
        "os.mkdir(\"data/train\")"
      ],
      "metadata": {
        "id": "Qy0hhPcZ1e8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trimming data as there are lot of training examples\n",
        "\n",
        "TRAIN_IMAGES_COUNT = 100\n",
        "\n",
        "for label in classes:\n",
        "  path = f'{TRAIN_PATH}/{label}'\n",
        "  img_files = os.listdir(path)\n",
        "  random_count_images = random.sample(img_files, TRAIN_IMAGES_COUNT)\n",
        "  new_path_for_label = f\"/content/data/train/{label}\"\n",
        "  os.mkdir(new_path_for_label)\n",
        "\n",
        "  for img_file in random_count_images:\n",
        "    shutil.move(f\"{path}/{img_file}\", new_path_for_label)"
      ],
      "metadata": {
        "id": "xTCB88Cd0Suz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image size has been specified in the research paper\n",
        "IMAGE_SIZE = (100,100)\n",
        "BATCH_SIZE = 32\n",
        "TRIMMED_TRAIN_PATH = '/content/data/train'\n",
        "TEST_PATH = '/content/raw/test/test'\n",
        "\n",
        "# To make data processing faster\n",
        "train_data=tf.keras.preprocessing.image_dataset_from_directory(directory=TRIMMED_TRAIN_PATH,\n",
        "                                                               image_size=IMAGE_SIZE,\n",
        "                                                               label_mode=\"categorical\",\n",
        "                                                               batch_size=BATCH_SIZE)\n",
        "\n",
        "test_data=tf.keras.preprocessing.image_dataset_from_directory(directory=TEST_PATH,\n",
        "                                                               image_size=IMAGE_SIZE,\n",
        "                                                               label_mode=\"categorical\",\n",
        "                                                               batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "cbJoJNH-xqYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "id": "ARrzAiaVg9bG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Describing modelling experiments"
      ],
      "metadata": {
        "id": "yDtentj-5F-0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- This notebook contains 7 models built to get the best **f1-score** on the test dataset. These models also include the models made by the researchers themselves.  \n",
        "- Models to be made:\n",
        "  1. **Model 0** : A simple model with fully connected multiple Dense layers; this model acts as a baseline.\n",
        "  1. **Model 1** : Multiple pairs of CNN and MaxPool layers with a  Dense layer in the end for classification.\n",
        "  1. **Model 2** : Replicate the best model (on the test set) from research paper; *should get better results from this.*\n",
        "  1. **Model 3** : Using transfer learning, exploit ResNet model for classification.\n",
        "  1. **Model 4** : Using transfer learning, exploit EfficientNetBx for classification.\n",
        "  1. **Model 5** : Use fine-tuned ResNet model for classification.\n",
        "  1. **Model 6** : Use fine-tuned EfficientNetBx for classification.\n",
        "- Get classification metrics for each model.\n"
      ],
      "metadata": {
        "id": "CsIhGbL_5xsc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory to save images of models' architectures\n",
        "!mkdir model_architectures"
      ],
      "metadata": {
        "id": "Q4oqp0a05Qm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 0 \n",
        "* **Layers:** 3 Dense layers\n",
        "* **Optimizer:** Adam\n",
        "* **Loss:** Cross entropy\n",
        "* **Epochs:** 5\n",
        "* **Callbacks:** `ModelCheckpoint`\n",
        "* **Validation data:** available"
      ],
      "metadata": {
        "id": "gr5XC0Uq_-yC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 0. Set random seed\n",
        "tf.random.set_seed(42)\n",
        "INPUT_SHAPE = (100,100,3)\n",
        "\n",
        "# 1. Create the model\n",
        "model_0 = tf.keras.Sequential([\n",
        "    layers.Flatten(input_shape=(100,100,3)),\n",
        "    layers.Input(shape=INPUT_SHAPE),\n",
        "    layers.Dense(128, activation=\"relu\"),\n",
        "    layers.Dense(128, activation=\"relu\"),\n",
        "    layers.Dense(128, activation=\"relu\"),\n",
        "    layers.Dense(131, activation=\"softmax\")\n",
        "], name=\"model_0_dense\")\n",
        "\n",
        "# 2. Compile the model\n",
        "model_0.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=\"Adam\",\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# 3. Get the summary\n",
        "model_0.summary()\n",
        "\n",
        "# 4. Fit the model\n",
        "history_model_0 = model_0.fit(train_data,\n",
        "                              epochs=10,\n",
        "                              validation_data=test_data,\n",
        "                              validation_steps=len(test_data)*0.15,\n",
        "                              callbacks=[create_model_checkpoint(model_name=model_0.name)])"
      ],
      "metadata": {
        "id": "GWBz8guhytLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model's architecture as an image\n",
        "plot_model(model_0, to_file='/content/model_architectures/model_0.png')\n",
        "\n",
        "# About the model history\n",
        "plot_loss_curves(history_model_0)"
      ],
      "metadata": {
        "id": "cqUcIZX622kS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading in the best weights\n",
        "best_weights_path = \"/content/model_experiments/model_0_dense\"\n",
        "model_0.load_weights(best_weights_path)\n",
        "\n",
        "# Evaluate on test set\n",
        "model_0.evaluate(test_data)"
      ],
      "metadata": {
        "id": "tPMO-JnrYxhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unravel dataset\n",
        "y_labels = []\n",
        "for images,labels in test_data.unbatch():\n",
        "  y_labels.append(labels.numpy().argmax())"
      ],
      "metadata": {
        "id": "J8XaSBWceQna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting predictions on test data\n",
        "model_0_preds_prob = model_0.predict(test_data, verbose=1)\n",
        "model_0_preds_classes = model_0_preds_prob.argmax(axis=1)\n",
        "\n",
        "# Getting a metrics report\n",
        "model_0_metrics = get_metrics(y_labels, model_0_preds_classes)\n",
        "model_0_metrics"
      ],
      "metadata": {
        "id": "fN4BAyhwZrcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 1 \n",
        "* **Layers:** Multiple Conv2D layers paired with MaxPool layers with a Dense layer at the end\n",
        "* **Optimizer:** Adam\n",
        "* **Loss:** Cross entropy\n",
        "* **Epochs:** 10\n",
        "* **Callbacks:** `ModelCheckpoint`\n",
        "* **Validation data:** available"
      ],
      "metadata": {
        "id": "bTZ_xAlHADd4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 0. Set random seed\n",
        "tf.random.set_seed(42)\n",
        "INPUT_SHAPE = (100,100,3)\n",
        "\n",
        "# 1. Create the model\n",
        "model_1 = tf.keras.Sequential([\n",
        "     tf.keras.layers.Conv2D(filters=10,\n",
        "                            kernel_size=3,\n",
        "                            activation=\"relu\",\n",
        "                            input_shape=INPUT_SHAPE),\n",
        "     tf.keras.layers.Conv2D(10,3,activation=\"relu\"),\n",
        "     tf.keras.layers.MaxPool2D(pool_size=2,\n",
        "                               padding=\"valid\"),\n",
        "     tf.keras.layers.Conv2D(10,3,activation=\"relu\"),\n",
        "     tf.keras.layers.Conv2D(10,3,activation=\"relu\"),\n",
        "     tf.keras.layers.MaxPool2D(2),\n",
        "     tf.keras.layers.Flatten(),\n",
        "     tf.keras.layers.Dense(131,activation=\"softmax\")\n",
        "], name=\"model_1_Conv2D\")\n",
        "\n",
        "# 2. Compile the model\n",
        "model_1.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=\"Adam\",\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# 3. Get the summary\n",
        "model_1.summary()\n",
        "\n",
        "# 4. Fit the model\n",
        "history_model_1 = model_1.fit(train_data,\n",
        "                              epochs=10,\n",
        "                              validation_data=test_data,\n",
        "                              validation_steps=len(test_data)*0.15,\n",
        "                              callbacks=[create_model_checkpoint(model_name=model_0.name)])"
      ],
      "metadata": {
        "id": "ahkcIbZQ3zVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# About the model history\n",
        "plot_loss_curves(history_model_1)"
      ],
      "metadata": {
        "id": "XbN-psnP4TjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading in the best weights\n",
        "best_weights_path = \"/content/model_experiments/model_1_Conv2D\"\n",
        "model_1.load_weights(best_weights_path)\n",
        "\n",
        "# Evaluate on test set\n",
        "model_1.evaluate(test_data)"
      ],
      "metadata": {
        "id": "FeyFbKYd4WCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting predictions on test data\n",
        "model_1_preds_prob = model_1.predict(test_data, verbose=1)\n",
        "model_1_preds_classes = model_1_preds_prob.argmax(axis=1)\n",
        "\n",
        "# Getting a metrics report\n",
        "model_1_metrics = get_metrics(y_labels, model_1_preds_classes)\n",
        "model_1_metrics"
      ],
      "metadata": {
        "id": "G8jQAWDr4d-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 2 \n",
        "* **Layers:** 3 Dense layers\n",
        "* **Optimizer:** Adam\n",
        "* **Loss:** Cross entropy\n",
        "* **Epochs:** 5\n",
        "* **Callbacks:** `ModelCheckpoint`\n",
        "* **Validation data:** available"
      ],
      "metadata": {
        "id": "7Z-aHSMMAEXj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 3\n",
        "* **Layers:** 3 Dense layers\n",
        "* **Optimizer:** Adam\n",
        "* **Loss:** Cross entropy\n",
        "* **Epochs:** 5\n",
        "* **Callbacks:** `ModelCheckpoint`\n",
        "* **Validation data:** available"
      ],
      "metadata": {
        "id": "hdsfE1MCAFbK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 4 \n",
        "* **Layers:** 3 Dense layers\n",
        "* **Optimizer:** Adam\n",
        "* **Loss:** Cross entropy\n",
        "* **Epochs:** 5\n",
        "* **Callbacks:** `ModelCheckpoint`\n",
        "* **Validation data:** available"
      ],
      "metadata": {
        "id": "YY9ejPFFAGUv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 5\n",
        "* **Layers:** 3 Dense layers\n",
        "* **Optimizer:** Adam\n",
        "* **Loss:** Cross entropy\n",
        "* **Epochs:** 5\n",
        "* **Callbacks:** `ModelCheckpoint`\n",
        "* **Validation data:** available"
      ],
      "metadata": {
        "id": "8YIH9eT5AHdM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 6\n",
        "* **Layers:** 3 Dense layers\n",
        "* **Optimizer:** Adam\n",
        "* **Loss:** Cross entropy\n",
        "* **Epochs:** 5\n",
        "* **Callbacks:** `ModelCheckpoint`\n",
        "* **Validation data:** available"
      ],
      "metadata": {
        "id": "Y4hHsWiWAIqr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Compare results and conclude experiments\n",
        "- Test each model on the given test dataset.\n",
        "- Use graphs and matrices to visualize results.\n",
        "- (*Optional*) Tune hyperparameters of the best model.\n",
        "- Compare best models results with researchers best model.\n",
        "- Export the best model.\n"
      ],
      "metadata": {
        "id": "uhXoIl1T_Ju3"
      }
    }
  ]
}