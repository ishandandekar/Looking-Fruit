{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNrJinLmAcVX"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ishandandekar/Looking-Fruit/blob/main/Looking_Fruit_nbk.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2t7p4-GpnQFQ"
      },
      "source": [
        "# Looking_Fruit\n",
        "\n",
        "ðŸ‘‹ Hello and welcome to the **Looking_Fruit** notebook. In this notebook I try to replicate the [Fruits-360](https://www.researchgate.net/publication/321475443_Fruit_recognition_from_images_using_deep_learning) research paper. In this paper, researchers have tried to classify images of **131** fruits and vegetables. The data used for these modelling experiments is provided by the paper researchers themselves."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fVSgcHVkTpS"
      },
      "outputs": [],
      "source": [
        "# Check for GPU\n",
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yK-K0_Oxp9RI"
      },
      "source": [
        "## Step 0: Defining the problem\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E957ywbEkgil"
      },
      "source": [
        "**Objective:**  \n",
        "To classify the images of various fruits and vegetables with best f1-score.  \n",
        "\n",
        "**Files:**\n",
        "- *Train*: This folder contains folders labelled as fruit's/vegetable's name. These subfolders contain images of the respective fruit/vegetable. This folder will be used for training purpose.\n",
        "- *Test*: This folder contains folders labelled as fruit's/vegetable's name. These subfolders contain images of the respective fruit/vegetable. This folder will be used for testing purpose."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yujoou29mCFK"
      },
      "source": [
        "## Step 1: Getting the data\n",
        "The data used for this project is publicly available on [Kaggle](https://www.kaggle.com/datasets/ishandandekar/fruitimagedataset).\n",
        "\n",
        "- Use Kaggle's API to download the data into Colab.\n",
        "- Get utility functions to help in future.\n",
        "- Configure data files to read using Python.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RriztHP9nLy1"
      },
      "outputs": [],
      "source": [
        "# Getting the helper functions script\n",
        "!wget https://raw.githubusercontent.com/ishandandekar/Looking_Fruit/main/scripts/helper_functions.py\n",
        "\n",
        "# Get the necessary functions from the python script\n",
        "from helper_functions import plot_loss_curves, unzip_data, create_model_checkpoint, create_early_stopping, get_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQk2Ny-zWEtP"
      },
      "source": [
        "About these helper functions (see documentation for better description):\n",
        "* **plot_loss_curves** : Plots a line graph (using matplotlib) to see changes in loss and accuracy during training.\n",
        "* **unzip_data** : Unzips a zip file to a directory\n",
        "* **create_model_checkpoint** : Creates a model checkpoint with only best weights (monitored over validation loss).\n",
        "* **create_early_stopping** : Creates an early stopping callback to prevent overfitting.\n",
        "* **get_metrics** : Returns a dictionary with classification metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxwTbHhbniZd"
      },
      "outputs": [],
      "source": [
        "# Install the kaggle library\n",
        "!pip install -q kaggle\n",
        "\n",
        "# Upload the Kaggle API keys\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "!mkdir ~/.kaggle\n",
        "\n",
        "# Copy the json file to the folder\n",
        "!cp kaggle.json ~/.kaggle\n",
        "\n",
        "# Change permissions for keys to work with the Kaggle API\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Download the dataset\n",
        "!kaggle datasets download -d ishandandekar/fruitimagedataset\n",
        "\n",
        "# Unzip data\n",
        "unzip_data('fruitimagedataset.zip', data_dir=\"raw\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2y7AyVsDpMeK"
      },
      "source": [
        "## Step 2: Know more about the data\n",
        "\n",
        "- Get the statistics about the data.\n",
        "- Check if the labels are imbalanced.\n",
        "- Visualize random samples in data.\n",
        "- (*If required*) Trim data.\n",
        "- (*If required*) Preprocess the data.\n",
        "- Make data processing faster using `ImageDataGenerator`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rruTT4WnpvsR"
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.metrics import CategoricalAccuracy, Precision, Recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jgdo_iPQp-hw"
      },
      "outputs": [],
      "source": [
        "# Setting up necessary variables\n",
        "TRAIN_PATH = '/content/raw/train/train/'\n",
        "TEST_PATH = '/content/raw/test/test/'\n",
        "RAW_DATA_PATH = '/content/raw'\n",
        "MODEL_VERBOSE = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJI7iNbnqHOp"
      },
      "outputs": [],
      "source": [
        "# Checking the number of classes\n",
        "classes = []\n",
        "\n",
        "for dirname, _, filenames in os.walk(RAW_DATA_PATH):\n",
        "    if dirname.startswith(f\"{TRAIN_PATH}\"):\n",
        "        classes.append(dirname[len(TRAIN_PATH):])\n",
        "\n",
        "print(f\"Total number of classes to deal with: {len(classes)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FaY0ocUwKP5"
      },
      "outputs": [],
      "source": [
        "# Show random classes present in the dataset\n",
        "list_of_five_random_labels = random.sample(classes,5)\n",
        "list_of_five_random_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fl9ktKX6wiaM"
      },
      "outputs": [],
      "source": [
        "# Number of images of each fruit/vegetable as a pandas.DataFrame\n",
        "\n",
        "# List to append the count of images\n",
        "number_of_images_train = []\n",
        "\n",
        "for label in classes:\n",
        "    path = f'{TRAIN_PATH}/{label}'\n",
        "    count = len(os.listdir(path))\n",
        "    number_of_images_train.append(count)\n",
        "\n",
        "train_image_count_df = pd.DataFrame({\"Label\":classes,\"Number of Images\":number_of_images_train})\n",
        "\n",
        "# To view first 10 rows of the dataframe\n",
        "train_image_count_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6L99UaG5iyQT"
      },
      "outputs": [],
      "source": [
        "# Label with most number of images\n",
        "print(f\"Label with most number of images:\")\n",
        "print(train_image_count_df.sort_values(\"Number of Images\",ascending=False).head(1))\n",
        "print(f\"Label with least number of images:\")\n",
        "print(train_image_count_df.sort_values(\"Number of Images\",ascending=True).head(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cv6G8PcTwtGI"
      },
      "outputs": [],
      "source": [
        "# Show random sample from training of a random fruit/vegetable\n",
        "\n",
        "random_label = random.choice(classes)\n",
        "sample_path = f'{TRAIN_PATH}/{random_label}'\n",
        "random_image= random.choice(os.listdir(sample_path))\n",
        "random_image_path = f'{sample_path}/{random_image}'\n",
        "\n",
        "img = mpimg.imread(random_image_path)\n",
        "imgplot = plt.imshow(img)\n",
        "plt.axis(False)\n",
        "plt.title(f'{random_label}')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qy0hhPcZ1e8V"
      },
      "outputs": [],
      "source": [
        "# Making new directories for trimmed training data\n",
        "os.mkdir(\"data\")\n",
        "os.mkdir(\"data/train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTCB88Cd0Suz"
      },
      "outputs": [],
      "source": [
        "# Trimming data as there are lot of training examples\n",
        "\n",
        "TRAIN_IMAGES_COUNT = 100\n",
        "\n",
        "for label in classes:\n",
        "  path = f'{TRAIN_PATH}/{label}'\n",
        "  img_files = os.listdir(path)\n",
        "  random_count_images = random.sample(img_files, TRAIN_IMAGES_COUNT)\n",
        "  new_path_for_label = f\"/content/data/train/{label}\"\n",
        "  os.mkdir(new_path_for_label)\n",
        "\n",
        "  for img_file in random_count_images:\n",
        "    shutil.move(f\"{path}/{img_file}\", new_path_for_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbJoJNH-xqYl"
      },
      "outputs": [],
      "source": [
        "# Image size has been specified in the research paper\n",
        "IMAGE_SIZE = (100,100)\n",
        "BATCH_SIZE = 32\n",
        "TRIMMED_TRAIN_PATH = '/content/data/train'\n",
        "TEST_PATH = '/content/raw/test/test'\n",
        "\n",
        "# To make data processing faster\n",
        "train_data=tf.keras.preprocessing.image_dataset_from_directory(directory=TRIMMED_TRAIN_PATH,\n",
        "                                                               image_size=IMAGE_SIZE,\n",
        "                                                               label_mode=\"categorical\",\n",
        "                                                               batch_size=BATCH_SIZE)\n",
        "\n",
        "test_data=tf.keras.preprocessing.image_dataset_from_directory(directory=TEST_PATH,\n",
        "                                                               image_size=IMAGE_SIZE,\n",
        "                                                               label_mode=\"categorical\",\n",
        "                                                               batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARrzAiaVg9bG"
      },
      "outputs": [],
      "source": [
        "# See an example of a batch of data and checking pixel values\n",
        "for images,labels in train_data.take(1):\n",
        "  for image in images:\n",
        "    print(f\"Shape of an image: {images.shape}\")\n",
        "    print(f\"Maximum in an image: {tf.math.reduce_max(images)}\")\n",
        "    break\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDtentj-5F-0"
      },
      "source": [
        "## Step 3: Describing modelling experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsIhGbL_5xsc"
      },
      "source": [
        "- This notebook contains 7 models built to get the best **f1-score** on the test dataset. These models also include the models made by the researchers themselves.  \n",
        "- Models to be made:\n",
        "  1. **Model 0** : simple model with fully connected multiple Dense layers; this model acts as a baseline.\n",
        "  1. **Model 1** : multiple pairs of CNN and MaxPool layers with a Flatten layer and Dense layer in the end for classification.\n",
        "  1. **Model 2** : exact same model that researchers used in their program script.\n",
        "  1. **Model 3** : uses **ResNet50** as its base, using transfer learning.\n",
        "  1. **Model 4** : uses **EfficientNetB0** under the hood unlike previous model\n",
        "  1. **Model 5** : uses a **fine-tuned ResNet50** as its base.\n",
        "  1. **Model 6** : uses a **fine-tuned EfficientNetB0** under its hood\n",
        "- Get classification metrics for each model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4oqp0a05Qm6"
      },
      "outputs": [],
      "source": [
        "# Directory to save images of models' architectures\n",
        "!mkdir model_architectures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gr5XC0Uq_-yC"
      },
      "source": [
        "#### Model 0 \n",
        "* **Layers:** 4 Dense layers\n",
        "* **Optimizer:** Adam\n",
        "* **Loss:** Cross entropy\n",
        "* **Epochs:** 10\n",
        "* **Callbacks:** `ModelCheckpoint`\n",
        "* **Validation data:** available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWBz8guhytLL"
      },
      "outputs": [],
      "source": [
        "# 0. Set random seed\n",
        "tf.random.set_seed(42)\n",
        "INPUT_SHAPE = (100,100,3)\n",
        "\n",
        "# 1. Create the model\n",
        "model_0 = tf.keras.Sequential([\n",
        "    layers.Flatten(input_shape=(100,100,3)),\n",
        "    layers.Input(shape=INPUT_SHAPE),\n",
        "    layers.Dense(128, activation=\"relu\"),\n",
        "    layers.Dense(128, activation=\"relu\"),\n",
        "    layers.Dense(128, activation=\"relu\"),\n",
        "    layers.Dense(131, activation=\"softmax\")\n",
        "], name=\"model_0_dense\")\n",
        "\n",
        "# 2. Compile the model\n",
        "model_0.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=\"Adam\",\n",
        "                metrics=[CategoricalAccuracy(), Precision(), Recall()])\n",
        "\n",
        "# 3. Get the summary\n",
        "model_0.summary()\n",
        "\n",
        "# 4. Fit the model\n",
        "history_model_0 = model_0.fit(train_data,\n",
        "                              epochs=10,\n",
        "                              validation_data=test_data,\n",
        "                              validation_steps=len(test_data)*0.15,\n",
        "                              verbose=MODEL_VERBOSE,\n",
        "                              callbacks=[create_model_checkpoint(model_name=model_0.name)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqUcIZX622kS"
      },
      "outputs": [],
      "source": [
        "# Save model's architecture as an image\n",
        "plot_model(model_0, to_file='/content/model_architectures/model_0.png')\n",
        "\n",
        "# About the model history\n",
        "plot_loss_curves(history_model_0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPMO-JnrYxhD"
      },
      "outputs": [],
      "source": [
        "# Loading in the best weights\n",
        "best_weights_path = \"/content/model_experiments/model_0_dense\"\n",
        "model_0.load_weights(best_weights_path)\n",
        "\n",
        "# Evaluate on test set\n",
        "loss_0, accuracy_0, precision_0, recall_0 = model_0.evaluate(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8XaSBWceQna"
      },
      "outputs": [],
      "source": [
        "# Unravel dataset\n",
        "y_labels = []\n",
        "for images,labels in test_data.unbatch():\n",
        "  y_labels.append(labels.numpy().argmax())\n",
        "y_labels = np.array(y_labels).reshape(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fN4BAyhwZrcX"
      },
      "outputs": [],
      "source": [
        "# Getting a metrics report\n",
        "model_0_metrics = get_metrics(loss_0, accuracy_0, precision_0, recall_0)\n",
        "model_0_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTZ_xAlHADd4"
      },
      "source": [
        "#### Model 1 \n",
        "* **Layers:** Multiple Conv2D layers paired with MaxPool layers with a Dense layer at the end\n",
        "* **Optimizer:** Adam\n",
        "* **Loss:** Cross entropy\n",
        "* **Epochs:** 25\n",
        "* **Callbacks:** `ModelCheckpoint`, `EarlyStopping`\n",
        "* **Validation data:** available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahkcIbZQ3zVm"
      },
      "outputs": [],
      "source": [
        "# 0. Set random seed\n",
        "tf.random.set_seed(42)\n",
        "INPUT_SHAPE = (100,100,3)\n",
        "\n",
        "# 1. Create the model\n",
        "model_1 = tf.keras.Sequential([\n",
        "     tf.keras.layers.Conv2D(filters=10,\n",
        "                            kernel_size=3,\n",
        "                            activation=\"relu\",\n",
        "                            input_shape=INPUT_SHAPE),\n",
        "     tf.keras.layers.Conv2D(10,3,activation=\"relu\"),\n",
        "     tf.keras.layers.MaxPool2D(pool_size=2,\n",
        "                               padding=\"valid\"),\n",
        "     tf.keras.layers.Conv2D(10,3,activation=\"relu\"),\n",
        "     tf.keras.layers.Conv2D(10,3,activation=\"relu\"),\n",
        "     tf.keras.layers.MaxPool2D(2),\n",
        "     tf.keras.layers.Flatten(),\n",
        "     tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "     tf.keras.layers.Dropout(0.2),\n",
        "     tf.keras.layers.Dense(131,activation=\"softmax\")\n",
        "], name=\"model_1_Conv2D\")\n",
        "\n",
        "# 2. Compile the model\n",
        "model_1.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=\"Adam\",\n",
        "                metrics=[CategoricalAccuracy(), Precision(), Recall()])\n",
        "\n",
        "# 3. Get the summary\n",
        "model_1.summary()\n",
        "\n",
        "# 4. Fit the model\n",
        "history_model_1 = model_1.fit(train_data,\n",
        "                              epochs=25,\n",
        "                              validation_data=test_data,\n",
        "                              validation_steps=len(test_data)*0.15,\n",
        "                              verbose=MODEL_VERBOSE,\n",
        "                              callbacks=[create_model_checkpoint(model_name=model_1.name), create_early_stopping()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XbN-psnP4TjC"
      },
      "outputs": [],
      "source": [
        "# Save model's architecture as an image\n",
        "plot_model(model_1, to_file='/content/model_architectures/model_1.png')\n",
        "\n",
        "# About the model history\n",
        "plot_loss_curves(history_model_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeyFbKYd4WCe"
      },
      "outputs": [],
      "source": [
        "# Loading in the best weights\n",
        "best_weights_path = \"/content/model_experiments/model_1_Conv2D\"\n",
        "model_1.load_weights(best_weights_path)\n",
        "\n",
        "# Evaluate on test set\n",
        "loss_1, accuracy_1, precision_1, recall_1 = model_1.evaluate(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8jQAWDr4d-L"
      },
      "outputs": [],
      "source": [
        "# Getting a metrics report\n",
        "model_1_metrics = get_metrics(loss_1, accuracy_1, precision_1, recall_1)\n",
        "model_1_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Z-aHSMMAEXj"
      },
      "source": [
        "#### Model 2 (Researchers' best model)\n",
        "* **Layers:** Multiple layer model including Conv2D, MaxPool, Dense, Dropouts and Flatten\n",
        "* **Optimizer:** Adadelta (with learning rate as 0.1)\n",
        "* **Loss:** Cross entropy\n",
        "* **Epochs:** 25\n",
        "* **Callbacks:** `ModelCheckpoint`, `EarlyStopping`\n",
        "* **Validation data:** available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zz60IDo9s_NH"
      },
      "outputs": [],
      "source": [
        "# 0. Set random seed\n",
        "tf.random.set_seed(42)\n",
        "INPUT_SHAPE = (100,100,3)\n",
        "\n",
        "# 1. Create the model (taken straight out of their code base)\n",
        "inputs = layers.Input(shape=INPUT_SHAPE, name=\"input_layer\")\n",
        "x = layers.Conv2D(16, (5, 5), strides=(1, 1), padding='same', name='conv1')(inputs)\n",
        "x = layers.Activation('relu', name='conv1_relu')(x)\n",
        "x = layers.MaxPooling2D((2, 2), strides=(2, 2), padding='valid', name='pool1')(x)\n",
        "x = layers.Conv2D(32, (5, 5), strides=(1, 1), padding='same', name='conv2')(x)\n",
        "x = layers.Activation('relu', name='conv2_relu')(x)\n",
        "x = layers.MaxPooling2D((2, 2), strides=(2, 2), padding='valid', name='pool2')(x)\n",
        "x = layers.Conv2D(64, (5, 5), strides=(1, 1), padding='same', name='conv3')(x)\n",
        "x = layers.Activation('relu', name='conv3_relu')(x)\n",
        "x = layers.MaxPooling2D((2, 2), strides=(2, 2), padding='valid', name='pool3')(x)\n",
        "x = layers.Conv2D(128, (5, 5), strides=(1, 1), padding='same', name='conv4')(x)\n",
        "x = layers.Activation('relu', name='conv4_relu')(x)\n",
        "x = layers.MaxPooling2D((2, 2), strides=(2, 2), padding='valid', name='pool4')(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(1024, activation='relu', name='fcl1')(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "x = layers.Dense(256, activation='relu', name='fcl2')(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "outputs = layers.Dense(131, activation='softmax', name='predictions')(x)\n",
        "model_2 = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"model_2_best_on_paper\")\n",
        "\n",
        "# 2. Compile the model\n",
        "model_2.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adadelta(learning_rate=0.1),\n",
        "                metrics=[CategoricalAccuracy(), Precision(), Recall()])\n",
        "\n",
        "# 3. Get the summary\n",
        "model_2.summary()\n",
        "\n",
        "# 4. Fit the model\n",
        "history_model_2 = model_2.fit(train_data,\n",
        "                              epochs=25,\n",
        "                              validation_data=test_data,\n",
        "                              validation_steps=len(test_data)*0.15,\n",
        "                              verbose=MODEL_VERBOSE,\n",
        "                              callbacks=[create_model_checkpoint(model_name=model_2.name), create_early_stopping()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dGClgqcucJw"
      },
      "outputs": [],
      "source": [
        "# Save model's architecture as an image\n",
        "plot_model(model_2, to_file='/content/model_architectures/model_2.png')\n",
        "\n",
        "# About the model history\n",
        "plot_loss_curves(history_model_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAiyTyQDupLw"
      },
      "outputs": [],
      "source": [
        "# Loading in the best weights\n",
        "best_weights_path = \"/content/model_experiments/model_2_best_on_paper\"\n",
        "model_2.load_weights(best_weights_path)\n",
        "\n",
        "# Evaluate on test set\n",
        "loss_2, accuracy_2, precision_2, recall_2 = model_2.evaluate(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrbD3KaOuty5"
      },
      "outputs": [],
      "source": [
        "# Getting a metrics report\n",
        "model_2_metrics = get_metrics(loss_2, accuracy_2, precision_2, recall_2)\n",
        "model_2_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdsfE1MCAFbK"
      },
      "source": [
        "#### Model 3\n",
        "* **Layers:** Using ResNet and various other layers to classify images\n",
        "* **Optimizer:** Adam\n",
        "* **Loss:** Cross entropy\n",
        "* **Epochs:** 25\n",
        "* **Callbacks:** `ModelCheckpoint`, `EarlyStopping`\n",
        "* **Validation data:** available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q67jMymRvB8f"
      },
      "outputs": [],
      "source": [
        "# 0. Set random seed\n",
        "tf.random.set_seed(42)\n",
        "INPUT_SHAPE = (100,100,3)\n",
        "\n",
        "# 1. Create the model (taken straight out of their code base)\n",
        "base_resnet_model = tf.keras.applications.resnet50.ResNet50(include_top=False)\n",
        "base_resnet_model.trainable = False\n",
        "inputs = layers.Input(shape=INPUT_SHAPE, name=\"input_layer\")\n",
        "scale = layers.Rescaling(scale=1./255)(inputs)\n",
        "x = base_resnet_model(scale)\n",
        "x = layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\n",
        "outputs = layers.Dense(131,activation=\"softmax\",name=\"output_layer\")(x)\n",
        "model_3 = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"model_3_freezed_ResNet\")\n",
        "\n",
        "# 2. Compile the model\n",
        "model_3.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=\"Adam\",\n",
        "                metrics=[CategoricalAccuracy(), Precision(), Recall()])\n",
        "\n",
        "# 3. Get the summary\n",
        "model_3.summary()\n",
        "\n",
        "# 4. Fit the model\n",
        "history_model_3 = model_3.fit(train_data,\n",
        "                              epochs=25,\n",
        "                              validation_data=test_data,\n",
        "                              validation_steps=len(test_data)*0.15,\n",
        "                              verbose=MODEL_VERBOSE,\n",
        "                              callbacks=[create_model_checkpoint(model_name=model_3.name), create_early_stopping()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKmOrxNx0dU4"
      },
      "outputs": [],
      "source": [
        "# Save model's architecture as an image\n",
        "plot_model(model_3, to_file='/content/model_architectures/model_3.png')\n",
        "\n",
        "# About the model history\n",
        "plot_loss_curves(history_model_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSzIoeT70hnD"
      },
      "outputs": [],
      "source": [
        "# Loading in the best weights\n",
        "best_weights_path = \"/content/model_experiments/model_3_freezed_ResNet\"\n",
        "model_3.load_weights(best_weights_path)\n",
        "\n",
        "# Evaluate on test set\n",
        "loss_3, accuracy_3, precision_3, recall_3 = model_3.evaluate(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vUSyQBq0uao"
      },
      "outputs": [],
      "source": [
        "# Getting a metrics report\n",
        "model_3_metrics = get_metrics(loss_3, accuracy_3, precision_3, recall_3)\n",
        "model_3_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YY9ejPFFAGUv"
      },
      "source": [
        "#### Model 4 \n",
        "* **Layers:** Using EfficientNetB0 (with freezed layers) and various other layers for classification\n",
        "* **Optimizer:** Adam\n",
        "* **Loss:** Cross entropy\n",
        "* **Epochs:** 25\n",
        "* **Callbacks:** `ModelCheckpoint`, `EarlyStopping`\n",
        "* **Validation data:** available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MU6w8Cgf1K2R"
      },
      "outputs": [],
      "source": [
        "# 0. Set random seed\n",
        "tf.random.set_seed(42)\n",
        "INPUT_SHAPE = (100,100,3)\n",
        "\n",
        "# 1. Create the model\n",
        "base_efficient_net_model=tf.keras.applications.EfficientNetB0(include_top=False)\n",
        "base_efficient_net_model.trainable=False\n",
        "inputs= layers.Input(shape=INPUT_SHAPE, name=\"input_layer\")\n",
        "x = base_efficient_net_model(inputs)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\n",
        "outputs=tf.keras.layers.Dense(131,activation=\"softmax\",name=\"output_layer\")(x)\n",
        "model_4 = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"model_4_freezed_EfficientNet\")\n",
        "\n",
        "# 2. Compile the model\n",
        "model_4.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=\"Adam\",\n",
        "                metrics=[CategoricalAccuracy(), Precision(), Recall()])\n",
        "\n",
        "# 3. Get the summary\n",
        "model_4.summary()\n",
        "\n",
        "# 4. Fit the model\n",
        "history_model_4 = model_4.fit(train_data,\n",
        "                              epochs=25,\n",
        "                              validation_data=test_data,\n",
        "                              validation_steps=len(test_data)*0.15,\n",
        "                              verbose=MODEL_VERBOSE,\n",
        "                              callbacks=[create_model_checkpoint(model_name=model_4.name), create_early_stopping()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u48O3Ou_2dqj"
      },
      "outputs": [],
      "source": [
        "# Save model's architecture as an image\n",
        "plot_model(model_4, to_file='/content/model_architectures/model_4.png')\n",
        "\n",
        "# About the model history\n",
        "plot_loss_curves(history_model_4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0oSZtYZ2jM_"
      },
      "outputs": [],
      "source": [
        "# Loading in the best weights\n",
        "best_weights_path = \"/content/model_experiments/model_4_freezed_EfficientNet\"\n",
        "model_4.load_weights(best_weights_path)\n",
        "\n",
        "# Evaluate on test set\n",
        "loss_4, accuracy_4, precision_4, recall_4 = model_4.evaluate(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPbrQ1102xIQ"
      },
      "outputs": [],
      "source": [
        "# Getting a metrics report\n",
        "model_4_metrics = get_metrics(loss_4, accuracy_4, precision_4, recall_4)\n",
        "model_4_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YIH9eT5AHdM"
      },
      "source": [
        "#### Model 5\n",
        "* **Layers:** Fine-tuned ResNet as the base with multiple other layers\n",
        "* **Optimizer:** Adam\n",
        "* **Loss:** Cross entropy\n",
        "* **Epochs:** 30, with `initial_epoch` set to the model 3's last epoch\n",
        "* **Callbacks:** `ModelCheckpoint`, `EarlyStopping`\n",
        "* **Validation data:** available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gk2zsuHc3uCO"
      },
      "outputs": [],
      "source": [
        "# 0. Set random seed\n",
        "tf.random.set_seed(42)\n",
        "INPUT_SHAPE = (100,100,3)\n",
        "\n",
        "# 1. Create the model\n",
        "base_resnet_model = tf.keras.applications.resnet50.ResNet50(include_top=False)\n",
        "base_resnet_model.trainable = False\n",
        "\n",
        "# Setting the base model to train (only on the last 10 layers)\n",
        "LAYERS_TRAINABLE = 10\n",
        "for layer in base_resnet_model.layers[-LAYERS_TRAINABLE:]:\n",
        "  layer.trainable = True\n",
        "\n",
        "inputs = layers.Input(shape=INPUT_SHAPE, name=\"input_layer\")\n",
        "scale = layers.Rescaling(scale=1./255)(inputs)\n",
        "x = base_resnet_model(scale)\n",
        "x = layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\n",
        "outputs = layers.Dense(131,activation=\"softmax\",name=\"output_layer\")(x)\n",
        "model_5 = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"model_5_finetuned_ResNet\")\n",
        "\n",
        "# 2. Compile the model\n",
        "model_5.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=\"Adam\",\n",
        "                metrics=[CategoricalAccuracy(), Precision(), Recall()])\n",
        "\n",
        "# 3. Get the summary\n",
        "model_5.summary()\n",
        "\n",
        "# 4. Fit the model\n",
        "history_model_5 = model_5.fit(train_data,\n",
        "                              epochs=30,\n",
        "                              initial_epoch=history_model_3.epoch[-1],\n",
        "                              validation_data=test_data,\n",
        "                              validation_steps=len(test_data)*0.15,\n",
        "                              verbose=MODEL_VERBOSE,\n",
        "                              callbacks=[create_model_checkpoint(model_name=model_5.name), create_early_stopping()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbm5sFqS5Vth"
      },
      "outputs": [],
      "source": [
        "# Save model's architecture as an image\n",
        "plot_model(model_5, to_file='/content/model_architectures/model_5.png')\n",
        "\n",
        "# About the model history\n",
        "plot_loss_curves(history_model_5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xq7OQP_253Z8"
      },
      "outputs": [],
      "source": [
        "# Loading in the best weights\n",
        "best_weights_path = \"/content/model_experiments/model_5_finetuned_ResNet\"\n",
        "model_5.load_weights(best_weights_path)\n",
        "\n",
        "# Evaluate on test set\n",
        "loss_5, accuracy_5, precision_5, recall_5 = model_5.evaluate(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcWq9XM25_1f"
      },
      "outputs": [],
      "source": [
        "# Getting a metrics report\n",
        "model_5_metrics = get_metrics(loss_5, accuracy_5, precision_5, recall_5)\n",
        "model_5_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4hHsWiWAIqr"
      },
      "source": [
        "#### Model 6\n",
        "* **Layers:** Fine-tuned EffificientNetB0 with other various layers\n",
        "* **Optimizer:** Adam\n",
        "* **Loss:** Cross entropy\n",
        "* **Epochs:** 30, with `initial_epoch` set as model 4's last epoch\n",
        "* **Callbacks:** `ModelCheckpoint`, `EarlyStopping`\n",
        "* **Validation data:** available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEL8YxLa7MWE"
      },
      "outputs": [],
      "source": [
        "# 0. Set random seed\n",
        "tf.random.set_seed(42)\n",
        "INPUT_SHAPE = (100,100,3)\n",
        "\n",
        "# 1. Create the model\n",
        "base_efficient_net_model=tf.keras.applications.EfficientNetB0(include_top=False)\n",
        "base_efficient_net_model.trainable=False\n",
        "\n",
        "# Setting the base model to train (only on the last 10 layers)\n",
        "LAYERS_TRAINABLE = 10\n",
        "for layer in base_efficient_net_model.layers[-LAYERS_TRAINABLE:]:\n",
        "  layer.trainable = True\n",
        "\n",
        "inputs= layers.Input(shape=INPUT_SHAPE, name=\"input_layer\")\n",
        "x = base_efficient_net_model(inputs)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\n",
        "outputs=tf.keras.layers.Dense(131,activation=\"softmax\",name=\"output_layer\")(x)\n",
        "model_6 = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"model_6_finetuned_EfficientNet\")\n",
        "\n",
        "# 2. Compile the model\n",
        "model_6.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=\"Adam\",\n",
        "                metrics=[CategoricalAccuracy(), Precision(), Recall()])\n",
        "\n",
        "# 3. Get the summary\n",
        "model_6.summary()\n",
        "\n",
        "# 4. Fit the model\n",
        "history_model_6 = model_6.fit(train_data,\n",
        "                              epochs=30,\n",
        "                              initial_epoch=history_model_4.epoch[-1],\n",
        "                              validation_data=test_data,\n",
        "                              validation_steps=len(test_data)*0.15,\n",
        "                              verbose=MODEL_VERBOSE,\n",
        "                              callbacks=[create_model_checkpoint(model_name=model_6.name), create_early_stopping()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwP1hfZ37l_7"
      },
      "outputs": [],
      "source": [
        "# Save model's architecture as an image\n",
        "plot_model(model_6, to_file='/content/model_architectures/model_6.png')\n",
        "\n",
        "# About the model history\n",
        "plot_loss_curves(history_model_6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TK1Ix6Bo7o1c"
      },
      "outputs": [],
      "source": [
        "# Loading in the best weights\n",
        "best_weights_path = \"/content/model_experiments/model_6_finetuned_EfficientNet\"\n",
        "model_6.load_weights(best_weights_path)\n",
        "\n",
        "# Evaluate on test set\n",
        "loss_6, accuracy_6, precision_6, recall_6 = model_6.evaluate(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-89PKkn_7yc-"
      },
      "outputs": [],
      "source": [
        "# Getting a metrics report\n",
        "model_6_metrics = get_metrics(loss_6, accuracy_6, precision_6, recall_6)\n",
        "model_6_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhXoIl1T_Ju3"
      },
      "source": [
        "## Step 4: Compare results and conclude experiments\n",
        "- Use graphs and matrices to visualize results.\n",
        "- (*Optional*) Tune hyperparameters of the best model.\n",
        "- Compare best models results with researchers best model.\n",
        "- Save and export the models (in .h5 format).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbXCA7X68D01"
      },
      "outputs": [],
      "source": [
        "# Dataframe of results\n",
        "results_df = pd.DataFrame({\"model_0_dense\": model_0_metrics,\n",
        "                           \"model_1_Conv2D\": model_1_metrics,\n",
        "                           \"model_2_best_on_paper\": model_2_metrics,\n",
        "                           \"model_3_freezed_ResNet\": model_3_metrics,\n",
        "                           \"model_4_freezed_EfficientNet\": model_4_metrics,\n",
        "                           \"model_5_finetuned_ResNet\": model_5_metrics,\n",
        "                           \"model_6_finetuned_EfficientNet\": model_6_metrics}).T"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_df[[\"Accuracy\", \"Precision\", \"Recall\"]].plot(kind=\"bar\", figsize=(14,7), title=\"Metrics of various models\", ylabel=\"Metrics\", xlabel=\"Models\");"
      ],
      "metadata": {
        "id": "T1o7b8m31Og6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4ZgWBJ6Aw8a"
      },
      "outputs": [],
      "source": [
        "# Creating directory to store all the models\n",
        "!mkdir saved_models\n",
        "\n",
        "# Saving models\n",
        "model_0.save(\"saved_models/model_0.h5\")\n",
        "model_1.save(\"saved_models/model_1.h5\")\n",
        "model_2.save(\"saved_models/model_2.h5\")\n",
        "model_3.save(\"saved_models/model_3.h5\")\n",
        "model_4.save(\"saved_models/model_4.h5\")\n",
        "model_5.save(\"saved_models/model_5.h5\")\n",
        "model_6.save(\"saved_models/model_6.h5\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}